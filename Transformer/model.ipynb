{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1cb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 40000 examples [00:00, 2057266.74 examples/s]\n",
      "Map: 100%|██████████| 40000/40000 [00:01<00:00, 32342.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2034, 6926, 1024, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 데이터 로드\n",
    "data = load_dataset(\"text\", data_files={\"train\": \"data/tiny_shakespeare.txt\"})\n",
    "\n",
    "# 토크나이저\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 토큰화\n",
    "def tokenize_fn(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=64)\n",
    "\n",
    "tok_data = data.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "print(tok_data[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33fd391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF Dataset을 바로 torch 텐서로 꺼내 쓰기 위한 포맷 지정\n",
    "tok_data = tok_data.with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85707ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([ 101, 2034, 6926, 1024,  102,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "print(tok_data[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TokPosEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, d_model, dropout):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(max_len, d_model)\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "       batch_size, seq_len = input_ids.shape\n",
    "       pos_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0).expand(batch_size, seq_len)\n",
    "       x = self.token_embedding(input_ids) + self.position_embedding(pos_ids)\n",
    "       return self.dropout(self.layernorm(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5f7ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 30522\n",
    "max_len    = 64\n",
    "d_model    = 256\n",
    "dropout    = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd9cd4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokPosEmbedding(\n",
       "  (token_embedding): Embedding(30522, 256)\n",
       "  (position_embedding): Embedding(64, 256)\n",
       "  (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = TokPosEmbedding(vocab_size, max_len, d_model, dropout)\n",
    "embedding = embedding.to(device)\n",
    "embedding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f93e5d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([16, 64])\n",
      "attention_mask shape: torch.Size([16, 64])\n",
      "embedding output: torch.Size([16, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "batch = tok_data[\"train\"][:16]\n",
    "\n",
    "input_ids = batch[\"input_ids\"].to(device)\n",
    "attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = embedding(input_ids)\n",
    "\n",
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(\"attention_mask shape:\", attention_mask.shape)\n",
    "print(\"embedding output:\", x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d86f17a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def build_causal_mask(seq_len, device):\n",
    "    mask = torch.full((1, 1, seq_len, seq_len), float(\"-inf\"), device = device) # 마지막 두 축 (s,s)는 \"쿼리 토큰 위치(행), 키 토큰 위치(열)를 볼 수 있나?\"\n",
    "    mask = torch.triu(mask, diagonal = 1)\n",
    "    return mask\n",
    "\n",
    "def combine_attention_mask(attn_mask_01, causal_mask):\n",
    "    is_pad = (attn_mask_01 == 0).unsqueeze(1).unsqueeze(2)  # (B,1,1,S) bool\n",
    "    minus_inf = torch.tensor(float(\"-inf\"), device=attn_mask_01.device)\n",
    "    pad_mask = torch.where(is_pad, minus_inf, torch.tensor(0.0, device=attn_mask_01.device))  # (B,1,1,S)\n",
    "    return causal_mask + pad_mask  # (B,1,S,S)로 브로드캐스트 합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0135ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f57ba026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):   \n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        \"\"\"\n",
    "        Q, K, V : (Batch_size, Num_head, Sequence_length, d_k)\n",
    "        attn_mask : (B, 1, S, S) 또는 (B, h, S, S)\n",
    "        \"\"\"\n",
    "        d_k = Q.size(-1) # 각 head의 차원의 크기\n",
    "\n",
    "        # Q와 K의 내적 -> 어텐션 유사도(score)\n",
    "        scores = torch.matmul(Q, K.transpose(-1,-2)) / (d_k ** 0.5)\n",
    "\n",
    "        # 마스크 더하기 (-inf가 있는 자리는 softmax 후 0이 됨)\n",
    "        if attn_mask is not None:\n",
    "            scores = scores + attn_mask\n",
    "\n",
    "        # softmax로 확률 분포화 (가장 관련 있는 토큰의 가중치 업!)\n",
    "        attn = F.softmax(scores, dim = -1)\n",
    "\n",
    "        # Value 가중합\n",
    "        out = torch.matmul(attn, V)\n",
    "\n",
    "        return out, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e600977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        # input을 Q/K/V로 projection\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.attn_score = ScaledDotProductAttention()\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def _split_heads(self, x):\n",
    "        \"\"\"\n",
    "        B: 배치크기\n",
    "        S: 시퀀스 길이(토큰 개수)\n",
    "        D: 전체 임베딩 차원\n",
    "        \"\"\"\n",
    "        B, S, D = x.shape\n",
    "        x = x.view(B, S, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "    def _merge_heads(self, x):\n",
    "        # x: (B,h,S,d_k) -> (B,S,D)\n",
    "        B, h, S, d_k = x.shape\n",
    "        x = x.transpose(1, 2).contiguous().view(B, S, h * d_k)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        \"\"\"\n",
    "        x: (B,S,d_model)\n",
    "        attn_mask: (B,1,S,S) 또는 (B,h,S,S)\n",
    "        \"\"\"\n",
    "        Q = self._split_heads(self.W_q(x))\n",
    "        K = self._split_heads(self.W_k(x))\n",
    "        V = self._split_heads(self.W_v(x))\n",
    "\n",
    "        out, attn = self.attn_score(Q, K, V, attn_mask)\n",
    "        out = self._merge_heads(out)\n",
    "        out = self.dropout(self.W_o(out))\n",
    "        return out, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48f9e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFFN(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(self.act(self.fc1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f5888c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94f1f353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token_id: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"pad_token_id:\", tokenizer.pad_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0246966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "735bec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = tok_data[\"train\"].train_test_split(test_size=0.05, seed=42)\n",
    "train_data = splits[\"train\"]\n",
    "valid_data = splits[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec921be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.ffn = PositionwiseFFN(d_model, d_ff, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        h, attn = self.mha(self.ln1(x), attn_mask=attn_mask)\n",
    "        x = x + self.dropout(h) # Residual\n",
    "        h2 = self.ffn(self.ln2(x))\n",
    "        x = x + self.dropout(h2)\n",
    "        return x, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc603e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17 수정본\n",
    "class DecoderOnlyLM(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, d_model, num_heads, d_ff, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = TokPosEmbedding(vocab_size, max_len, d_model, dropout)\n",
    "        self.layers = nn.ModuleList([  # layer -> layers로 수정\n",
    "            TransformerBlock(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.ln_f = nn.LayerNorm(d_model)\n",
    "        self.lm_head = nn.Linear(d_model, vocab_size, bias=False)\n",
    "\n",
    "        # Weight tying: 임베딩 가중치와 LM head 공유\n",
    "        self.lm_head.weight = self.embedding.token_embedding.weight\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        x = self.embedding(input_ids)\n",
    "        batch_size, sequence_length = input_ids.size()\n",
    "\n",
    "        causal = build_causal_mask(sequence_length, device=input_ids.device)\n",
    "        if attention_mask is not None:\n",
    "            attn_mask = combine_attention_mask(attention_mask, causal)\n",
    "        else:\n",
    "            attn_mask = causal\n",
    "\n",
    "        attns=[]\n",
    "        for block in self.layers:  # 이제 정상 동작\n",
    "            x, attn = block(x, attn_mask)\n",
    "            attns.append(attn)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        return logits, attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dff5ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "num_layers = 4\n",
    "num_heads  = 8\n",
    "d_ff       = 4 * d_model      # 보통 4*d_model\n",
    "lr         = 3e-4\n",
    "weight_decay = 0.01\n",
    "pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0\n",
    "\n",
    "model = DecoderOnlyLM(\n",
    "    vocab_size=vocab_size,\n",
    "    max_len=max_len,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    d_ff=d_ff,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.95), weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3927162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(examples):\n",
    "    # with_format(\"torch\") 덕분에 텐서로 바로 스택 가능\n",
    "    return {\n",
    "        \"input_ids\": torch.stack([e[\"input_ids\"] for e in examples]),\n",
    "        \"attention_mask\": torch.stack([e[\"attention_mask\"] for e in examples]),\n",
    "    }\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "def make_lm_batch(batch):\n",
    "    input_ids = batch[\"input_ids\"].to(device)          # (B,S)\n",
    "    attn_mask = batch[\"attention_mask\"].to(device)     # (B,S)\n",
    "\n",
    "    # 다음 토큰 예측: 입력/라벨 한 칸 시프트\n",
    "    x_in  = input_ids[:, :-1].contiguous()             # (B,S-1)\n",
    "    y_out = input_ids[:, 1:].contiguous()              # (B,S-1)\n",
    "    m_in  = attn_mask[:, :-1].contiguous()             # (B,S-1)\n",
    "    return x_in, m_in, y_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2ad872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, clip=1.0):\n",
    "    model.train()\n",
    "    total_loss, total_tokens = 0.0, 0\n",
    "    for step, batch in enumerate(loader):\n",
    "        x_in, m_in, y_out = make_lm_batch(batch)\n",
    "        logits, _ = model(x_in, attention_mask=m_in)   # (B,S-1,V)\n",
    "\n",
    "        B, S1, V = logits.shape\n",
    "        loss = criterion(logits.view(B*S1, V), y_out.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # 통계: 유효 토큰(패딩 제외)\n",
    "        n_valid = (y_out != pad_id).sum().item()\n",
    "        total_loss += loss.item() * n_valid\n",
    "        total_tokens += n_valid\n",
    "\n",
    "        if (step+1) % 50 == 0:\n",
    "            ppl = math.exp(total_loss / max(total_tokens, 1))\n",
    "            print(f\"[train step {step+1}] loss(avg)={total_loss/total_tokens:.4f} | ppl={ppl:.2f}\")\n",
    "\n",
    "    avg_loss = total_loss / max(total_tokens, 1)\n",
    "    return avg_loss, math.exp(avg_loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_tokens = 0.0, 0\n",
    "    for batch in loader:\n",
    "        x_in, m_in, y_out = make_lm_batch(batch)\n",
    "        logits, _ = model(x_in, attention_mask=m_in)\n",
    "        B, S1, V = logits.shape\n",
    "        loss = criterion(logits.view(B*S1, V), y_out.view(-1))\n",
    "\n",
    "        n_valid = (y_out != pad_id).sum().item()\n",
    "        total_loss += loss.item() * n_valid\n",
    "        total_tokens += n_valid\n",
    "\n",
    "    avg_loss = total_loss / max(total_tokens, 1)\n",
    "    return avg_loss, math.exp(avg_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f015778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train step 50] loss(avg)=43.8364 | ppl=10912167756289087488.00\n",
      "[train step 100] loss(avg)=34.2628 | ppl=758833594836645.88\n",
      "[train step 150] loss(avg)=29.9449 | ppl=10113906046277.23\n",
      "[train step 200] loss(avg)=27.0795 | ppl=576092854723.49\n",
      "[train step 250] loss(avg)=24.9267 | ppl=66915520908.06\n",
      "[train step 300] loss(avg)=23.1895 | ppl=11777530997.74\n",
      "[train step 350] loss(avg)=21.8241 | ppl=3006641202.49\n",
      "[train step 400] loss(avg)=20.6322 | ppl=912939770.61\n",
      "[train step 450] loss(avg)=19.6395 | ppl=338329479.27\n",
      "[train step 500] loss(avg)=18.7655 | ppl=141172394.72\n",
      "[train step 550] loss(avg)=17.9779 | ppl=64227199.57\n",
      "[train step 600] loss(avg)=17.2921 | ppl=32347759.62\n",
      "[train step 650] loss(avg)=16.6771 | ppl=17488582.51\n",
      "[train step 700] loss(avg)=16.1293 | ppl=10112376.37\n",
      "[train step 750] loss(avg)=15.6384 | ppl=6189789.33\n",
      "[train step 800] loss(avg)=15.1928 | ppl=3964049.26\n",
      "[train step 850] loss(avg)=14.7857 | ppl=2638421.56\n",
      "[train step 900] loss(avg)=14.4120 | ppl=1815673.55\n",
      "[train step 950] loss(avg)=14.0684 | ppl=1287676.60\n",
      "[train step 1000] loss(avg)=13.7523 | ppl=938718.65\n",
      "[train step 1050] loss(avg)=13.4641 | ppl=703714.17\n",
      "[train step 1100] loss(avg)=13.1918 | ppl=535963.11\n",
      "[train step 1150] loss(avg)=12.9413 | ppl=417185.16\n",
      "[epoch 1] train_loss=12.7609 (ppl=348314.08) | valid_loss=6.3370 (ppl=565.08)\n",
      "  -> checkpoint saved: decoder_only_ckpt.pt\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1  # 우선 1 에폭만 돌려보기(스모크 테스트)\n",
    "best_val = float(\"inf\")\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_ppl = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    va_loss, va_ppl = evaluate(model, valid_loader, criterion)\n",
    "    print(f\"[epoch {epoch}] train_loss={tr_loss:.4f} (ppl={tr_ppl:.2f}) | valid_loss={va_loss:.4f} (ppl={va_ppl:.2f})\")\n",
    "\n",
    "    # 간단 체크포인트(유효성 손실이 좋아지면 저장)\n",
    "    if va_loss < best_val:\n",
    "        best_val = va_loss\n",
    "        torch.save({\"model\": model.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"config\": {\n",
    "                        \"vocab_size\": vocab_size, \"max_len\": max_len, \"d_model\": d_model,\n",
    "                        \"num_heads\": num_heads, \"d_ff\": d_ff, \"num_layers\": num_layers, \"dropout\": dropout\n",
    "                    }}, \"decoder_only_ckpt.pt\")\n",
    "        print(\"  -> checkpoint saved: decoder_only_ckpt.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ddfbcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAMPLE ===\n",
      " to be, or not to be o ' d what : : ' t a ' d in the aus his must come, and i ' do that that that ay oure a. i think of, more but that a us\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, tokenizer, prompt_text, max_new_tokens=80, temperature=1.0, top_k=None):\n",
    "    model.eval()\n",
    "    enc = tokenizer(prompt_text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    x = enc[\"input_ids\"].to(device)   # (1, S0)\n",
    "    attn_mask_ones = torch.ones_like(x, dtype=torch.long)  # 프롬프트는 패딩 없음\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # 길이 유지: (최근 max_len 토큰만)\n",
    "        x_cond = x[:, -max_len:]\n",
    "        m_cond = attn_mask_ones[:, -max_len:]\n",
    "\n",
    "        logits, _ = model(x_cond, attention_mask=m_cond)\n",
    "        next_logits = logits[:, -1, :] / temperature  # 마지막 토큰의 분포\n",
    "\n",
    "        if top_k is not None:\n",
    "            v, ix = torch.topk(next_logits, top_k)\n",
    "            mask = next_logits < v[:, [-1]]\n",
    "            next_logits = next_logits.masked_fill(mask, -float(\"inf\"))\n",
    "\n",
    "        probs = F.softmax(next_logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)  # (1,1)\n",
    "\n",
    "        x = torch.cat([x, next_id], dim=1)\n",
    "        attn_mask_ones = torch.ones_like(x, dtype=torch.long)\n",
    "\n",
    "    text = tokenizer.batch_decode(x.tolist(), skip_special_tokens=True)[0]\n",
    "    return text\n",
    "\n",
    "# 예시\n",
    "sample = generate(model, tokenizer, prompt_text=\"To be, or not to be\", max_new_tokens=60, temperature=1.0, top_k=50)\n",
    "print(\"=== SAMPLE ===\\n\", sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55fcfeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o romeo, romeo! wherefore art thou romeo? see ' ll in the you it is, all a no a king you think, what you i ' ll a us us us us york my york you his, i will me on : in ' d to! ' d his : how ' d to? ' d '\n"
     ]
    }
   ],
   "source": [
    "# 저장했던 체크포인트 불러와서 바로 생성만 해보기\n",
    "ckpt = torch.load(\"decoder_only_ckpt.pt\", map_location=device)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "print(generate(model, tokenizer, \"O Romeo, Romeo! wherefore art thou Romeo?\", 80, 0.9, top_k=40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731fe25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
