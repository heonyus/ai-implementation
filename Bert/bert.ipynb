{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d2e5d6bbbef473ea0680b97c5ba6ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b2407b780384cb3b831e1c81bc48f80",
              "IPY_MODEL_f098c8a260d64249968bce6b7df7e146",
              "IPY_MODEL_c083ef4c227b47e791327e83cf1aaaf8"
            ],
            "layout": "IPY_MODEL_000998bc98254570949e8714ccb351cc"
          }
        },
        "2b2407b780384cb3b831e1c81bc48f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e7e382952ed41dfadcd028e1a1248a5",
            "placeholder": "​",
            "style": "IPY_MODEL_d558b871cd9140b38de0d0a9dcf30e2e",
            "value": "Map: 100%"
          }
        },
        "f098c8a260d64249968bce6b7df7e146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee7e026a9a14ff8b574b40374c4accd",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad0ee927fe294379988dc2f6e10c66a6",
            "value": 36718
          }
        },
        "c083ef4c227b47e791327e83cf1aaaf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8a68a810a8c47b0b42935ec78fe3c5f",
            "placeholder": "​",
            "style": "IPY_MODEL_3390c0b6d8874474ab195f48554146c5",
            "value": " 36718/36718 [00:17&lt;00:00, 4080.69 examples/s]"
          }
        },
        "000998bc98254570949e8714ccb351cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e7e382952ed41dfadcd028e1a1248a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d558b871cd9140b38de0d0a9dcf30e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ee7e026a9a14ff8b574b40374c4accd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad0ee927fe294379988dc2f6e10c66a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8a68a810a8c47b0b42935ec78fe3c5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3390c0b6d8874474ab195f48554146c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7fR6ptocpYI",
        "outputId": "98666f5f-6499-4a06-d1c9-7ef259930dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "raw_dataset = load_dataset(\"Salesforce/wikitext\", \"wikitext-2-raw-v1\")  # train/validation/test\n",
        "train_dataset = raw_dataset[\"train\"]"
      ],
      "metadata": {
        "id": "zVlBLNaodu4K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6L2Zp-DjiKu",
        "outputId": "52260163-de68-4bde-c890-92f5a7581709"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 4358\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 36718\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 3760\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eAPi__oe3Ch",
        "outputId": "772ed519-7e80-45bd-bd6d-b196e5e4dc2c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['',\n",
              "  ' = Valkyria Chronicles III = \\n',\n",
              "  '',\n",
              "  ' Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n',\n",
              "  \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\"]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_sentences = []\n",
        "\n",
        "for one_row in train_dataset:\n",
        "  sentence = one_row['text']\n",
        "  sentence = sentence.strip()\n",
        "  if sentence != '':\n",
        "    all_sentences.append(sentence)\n",
        "\n",
        "print(\"전체 문장 개수:\", len(all_sentences))\n",
        "print(\"앞의 예시 문장 3개:\", all_sentences[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9sLNHzfhCS1",
        "outputId": "3a5bb8dd-1c54-4bd1-d516-080fa2af87a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 문장 개수: 23767\n",
            "앞의 예시 문장 3개: ['= Valkyria Chronicles III =', 'Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" .', \"The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n .\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequency = {}\n",
        "\n",
        "for one_sentence in all_sentences:\n",
        "  words = one_sentence.split()\n",
        "  for one_word in words:\n",
        "    token = \" \".join(list(one_word)) + \" </w>\"\n",
        "\n",
        "    if token not in word_frequency:\n",
        "      word_frequency[token] = 1\n",
        "    else:\n",
        "      word_frequency[token] += 1\n",
        "\n",
        "print(\"사전에 들어간 단어 개수:\", len(word_frequency))\n",
        "print(\"예시 5개:\")\n",
        "for index, (token, count) in enumerate(word_frequency.items()):\n",
        "    if index >= 5:\n",
        "        break\n",
        "    print(token, \":\", count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0WeSZuDkIBU",
        "outputId": "76b17ed7-3464-4805-b954-39b4ba01cd76"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사전에 들어간 단어 개수: 76616\n",
            "예시 5개:\n",
            "= </w> : 29570\n",
            "V a l k y r i a </w> : 54\n",
            "C h r o n i c l e s </w> : 47\n",
            "I I I </w> : 231\n",
            "S e n j ō </w> : 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def get_pair_statistics(vocab):\n",
        "\n",
        "  \"\"\"\n",
        "  vocab: {'t h e </w>': 1245, 'p l a y </w>': 45, ...}\n",
        "  return: {('t', 'h'): 등장횟수, ('p', 'l'): 등장횟수, ...}\n",
        "  \"\"\"\n",
        "\n",
        "  pair_freq = defaultdict(int)\n",
        "\n",
        "  for word, freq in vocab.items():\n",
        "    symbols = word.split()\n",
        "\n",
        "    for i in range(len(symbols) - 1):\n",
        "      left = symbols[i]\n",
        "      right = symbols[i + 1]\n",
        "      pair_freq[(left, right)] += freq\n",
        "\n",
        "  return pair_freq"
      ],
      "metadata": {
        "id": "vBQ9y_n_lfwg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pair_stats = get_pair_statistics(word_frequency)\n",
        "\n",
        "print(\"쌍(pair) 개수:\", len(pair_stats))\n",
        "print(\"예시 10개:\")\n",
        "for i, (pair, freq) in enumerate(pair_stats.items()):\n",
        "    if i >= 10:\n",
        "        break\n",
        "    print(pair, \":\", freq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TxJM6C8m69N",
        "outputId": "c3792d06-f221-4a90-da4d-1459834358c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "쌍(pair) 개수: 5504\n",
            "예시 10개:\n",
            "('=', '</w>') : 29570\n",
            "('V', 'a') : 1021\n",
            "('a', 'l') : 68991\n",
            "('l', 'k') : 1329\n",
            "('k', 'y') : 758\n",
            "('y', 'r') : 972\n",
            "('r', 'i') : 53566\n",
            "('i', 'a') : 20723\n",
            "('a', '</w>') : 56830\n",
            "('C', 'h') : 5322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 쌍(pair) 중에서 가장 자주 등장한 한 쌍 찾기\n",
        "most_frequent_pair = max(pair_stats, key=pair_stats.get)\n",
        "print(\"가장 자주 등장한 쌍:\", most_frequent_pair, \"→ 등장 횟수:\", pair_stats[most_frequent_pair])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ8KXas_m7hV",
        "outputId": "5c180d7d-f27a-4e8b-a897-2ee596ba5407"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가장 자주 등장한 쌍: ('e', '</w>') → 등장 횟수: 315788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def merge_vocab_pair(pair_to_merge, vocab_in):\n",
        "    \"\"\"\n",
        "    pair_to_merge: ('a', 'l') 같은 쌍\n",
        "    vocab_in: {'a l l </w>': 2, 'a l p h a </w>': 5, ...}\n",
        "    return: 병합 후 새 vocab\n",
        "    \"\"\"\n",
        "\n",
        "    # 정규식으로 'a l' 패턴을 찾기 (양쪽에 공백이 있는 경우만)\n",
        "    pattern = re.escape(' '.join(pair_to_merge))\n",
        "    pattern = r'(?<!\\S)' + pattern + r'(?!\\S)'\n",
        "\n",
        "    new_vocab = {}\n",
        "    for word, freq in vocab_in.items():\n",
        "        # 'a l' → 'al' 로 교체\n",
        "        new_word = re.sub(pattern, ''.join(pair_to_merge), word)\n",
        "        new_vocab[new_word] = freq\n",
        "    return new_vocab\n"
      ],
      "metadata": {
        "id": "HQlxBzmXnplE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 자주 등장한 쌍을 병합\n",
        "merged_vocab = merge_vocab_pair(most_frequent_pair, word_frequency)\n",
        "\n",
        "print(\"병합 전 단어 수:\", len(word_frequency))\n",
        "print(\"병합 후 단어 수:\", len(merged_vocab))\n",
        "\n",
        "# 병합 결과 예시 보기\n",
        "for i, (word, freq) in enumerate(merged_vocab.items()):\n",
        "    if i >= 5:\n",
        "        break\n",
        "    print(word, \":\", freq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkQ8z_irn_Qt",
        "outputId": "93786afc-226d-447d-f443-3b072fccfcff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "병합 전 단어 수: 76616\n",
            "병합 후 단어 수: 76616\n",
            "= </w> : 29570\n",
            "V a l k y r i a </w> : 54\n",
            "C h r o n i c l e s </w> : 47\n",
            "I I I </w> : 231\n",
            "S e n j ō </w> : 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "def train_wordpiece(vocab, num_merges):\n",
        "    \"\"\"\n",
        "    vocab: {'p l a y </w>': 3, 't h e </w>': 1245, ...}\n",
        "    num_merges: 병합 횟수 (예: 10이면 10번 반복)\n",
        "    \"\"\"\n",
        "    current_vocab = copy.deepcopy(vocab)\n",
        "    merges = []  # 병합된 쌍들을 기록할 리스트\n",
        "\n",
        "    for merge_step in range(num_merges):\n",
        "        print(f\"\\n[{merge_step+1}번째 병합 단계]\")\n",
        "\n",
        "        # 1. 문자쌍 등장 횟수 계산\n",
        "        pair_stats = get_pair_statistics(current_vocab)\n",
        "\n",
        "        # 2. 가장 자주 등장한 쌍 선택\n",
        "        best_pair = max(pair_stats, key=pair_stats.get)\n",
        "        print(\"가장 자주 등장한 쌍:\", best_pair, \"→\", pair_stats[best_pair], \"번\")\n",
        "\n",
        "        # 3. 병합 수행\n",
        "        current_vocab = merge_vocab_pair(best_pair, current_vocab)\n",
        "        merges.append(best_pair)\n",
        "\n",
        "        # 4. 예시 단어 몇 개만 출력\n",
        "        print(\"병합 후 예시 단어 5개:\")\n",
        "        for i, (word, freq) in enumerate(current_vocab.items()):\n",
        "            if i >= 5: break\n",
        "            print(\" \", word)\n",
        "\n",
        "    return current_vocab, merges\n"
      ],
      "metadata": {
        "id": "n9DgKBN8oBFT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_vocab, merge_history = train_wordpiece(word_frequency, num_merges=10)\n",
        "\n",
        "print(\"\\n✅ 최종 병합된 쌍 10개:\")\n",
        "for i, pair in enumerate(merge_history):\n",
        "    print(f\"{i+1}. {pair}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TEpkBJaoRbC",
        "outputId": "40d6f29e-0eb8-4223-a6da-fa3ad63c350f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1번째 병합 단계]\n",
            "가장 자주 등장한 쌍: ('e', '</w>') → 315788 번\n",
            "병합 후 예시 단어 5개:\n",
            "  = </w>\n",
            "  V a l k y r i a </w>\n",
            "  C h r o n i c l e s </w>\n",
            "  I I I </w>\n",
            "  S e n j ō </w>\n",
            "\n",
            "[2번째 병합 단계]\n",
            "가장 자주 등장한 쌍: ('s', '</w>') → 228389 번\n",
            "병합 후 예시 단어 5개:\n",
            "  = </w>\n",
            "  V a l k y r i a </w>\n",
            "  C h r o n i c l e s</w>\n",
            "  I I I </w>\n",
            "  S e n j ō </w>\n",
            "\n",
            "[3번째 병합 단계]\n",
            "가장 자주 등장한 쌍: ('t', 'h') → 199390 번\n",
            "병합 후 예시 단어 5개:\n",
            "  = </w>\n",
            "  V a l k y r i a </w>\n",
            "  C h r o n i c l e s</w>\n",
            "  I I I </w>\n",
            "  S e n j ō </w>\n",
            "\n",
            "[4번째 병합 단계]\n",
            "가장 자주 등장한 쌍: ('d', '</w>') → 187275 번\n",
            "병합 후 예시 단어 5개:\n",
            "  = </w>\n",
            "  V a l k y r i a </w>\n",
            "  C h r o n i c l e s</w>\n",
            "  I I I </w>\n",
            "  S e n j ō </w>\n",
            "\n",
            "[5번째 병합 단계]\n",
            "가장 자주 등장한 쌍: ('n', '</w>') → 171069 번\n",
            "병합 후 예시 단어 5개:\n",
            "  = </w>\n",
            "  V a l k y r i a </w>\n",
            "  C h r o n i c l e s</w>\n",
            "  I I I </w>\n",
            "  S e n j ō </w>\n",
            "\n",
            "[6번째 병합 단계]\n",
            "가장 자주 등장한 쌍: ('e', 'r') → 137656 번\n",
            "병합 후 예시 단어 5개:\n",
            "  = </w>\n",
            "  V a l k y r i a </w>\n",
            "  C h r o n i c l e s</w>\n",
            "  I I I </w>\n",
            "  S e n j ō </w>\n",
            "\n",
            "[7번째 병합 단계]\n",
            "가장 자주 등장한 쌍: ('t', '</w>') → 128094 번\n",
            "병합 후 예시 단어 5개:\n",
            "  = </w>\n",
            "  V a l k y r i a </w>\n",
            "  C h r o n i c l e s</w>\n",
            "  I I I </w>\n",
            "  S e n j ō </w>\n",
            "\n",
            "[8번째 병합 단계]\n",
            "가장 자주 등장한 쌍: ('th', 'e</w>') → 113196 번\n",
            "병합 후 예시 단어 5개:\n",
            "  = </w>\n",
            "  V a l k y r i a </w>\n",
            "  C h r o n i c l e s</w>\n",
            "  I I I </w>\n",
            "  S e n j ō </w>\n",
            "\n",
            "[9번째 병합 단계]\n",
            "가장 자주 등장한 쌍: ('i', 'n') → 111793 번\n",
            "병합 후 예시 단어 5개:\n",
            "  = </w>\n",
            "  V a l k y r i a </w>\n",
            "  C h r o n i c l e s</w>\n",
            "  I I I </w>\n",
            "  S e n j ō </w>\n",
            "\n",
            "[10번째 병합 단계]\n",
            "가장 자주 등장한 쌍: ('a', 'n') → 105740 번\n",
            "병합 후 예시 단어 5개:\n",
            "  = </w>\n",
            "  V a l k y r i a </w>\n",
            "  C h r o n i c l e s</w>\n",
            "  I I I </w>\n",
            "  S e n j ō </w>\n",
            "\n",
            "✅ 최종 병합된 쌍 10개:\n",
            "1. ('e', '</w>')\n",
            "2. ('s', '</w>')\n",
            "3. ('t', 'h')\n",
            "4. ('d', '</w>')\n",
            "5. ('n', '</w>')\n",
            "6. ('e', 'r')\n",
            "7. ('t', '</w>')\n",
            "8. ('th', 'e</w>')\n",
            "9. ('i', 'n')\n",
            "10. ('a', 'n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_by_wordpiece(text, merge_rules):\n",
        "    \"\"\"\n",
        "    text: 입력 문장 (예: \"Valkyria\")\n",
        "    merge_rules: [('a','l'), ('r','i'), ('a','</w>'), ...] 병합 순서\n",
        "    \"\"\"\n",
        "    # 1️⃣ 문자 단위로 쪼개기 + 단어 끝에 </w> 붙이기\n",
        "    symbols = list(text) + [\"</w>\"]\n",
        "    print(f\"\\n[초기 문자 단위 분해]\\n{text} → {' '.join(symbols)}\")\n",
        "\n",
        "    # 2️⃣ 병합 규칙 순서대로 적용\n",
        "    for step, (left, right) in enumerate(merge_rules):\n",
        "        i = 0\n",
        "        new_symbols = []\n",
        "        while i < len(symbols):\n",
        "            # 현재 문자와 다음 문자를 병합 대상과 비교\n",
        "            if i < len(symbols) - 1 and symbols[i] == left and symbols[i + 1] == right:\n",
        "                merged = left + right\n",
        "                new_symbols.append(merged)\n",
        "                i += 2  # 두 글자 건너뜀\n",
        "            else:\n",
        "                new_symbols.append(symbols[i])\n",
        "                i += 1\n",
        "\n",
        "        symbols = new_symbols  # 갱신\n",
        "        print(f\"[{step+1:02d}단계 병합 후] {' '.join(symbols)}\")\n",
        "\n",
        "    # 3️⃣ 마지막에 </w> 제거하고 결과 반환\n",
        "    if symbols[-1] == \"</w>\":\n",
        "        symbols = symbols[:-1]\n",
        "    return symbols\n"
      ],
      "metadata": {
        "id": "W_XHYsYUoSxF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_word = \"Valkyria\"\n",
        "result_tokens = tokenize_by_wordpiece(test_word, merge_history[:10])  # 앞의 10개 규칙만 사용\n",
        "\n",
        "print(\"\\n최종 토큰화 결과:\", result_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5f20Y9bopXW",
        "outputId": "581a1e38-c15f-4d69-b33a-3b942df62810"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[초기 문자 단위 분해]\n",
            "Valkyria → V a l k y r i a </w>\n",
            "[01단계 병합 후] V a l k y r i a </w>\n",
            "[02단계 병합 후] V a l k y r i a </w>\n",
            "[03단계 병합 후] V a l k y r i a </w>\n",
            "[04단계 병합 후] V a l k y r i a </w>\n",
            "[05단계 병합 후] V a l k y r i a </w>\n",
            "[06단계 병합 후] V a l k y r i a </w>\n",
            "[07단계 병합 후] V a l k y r i a </w>\n",
            "[08단계 병합 후] V a l k y r i a </w>\n",
            "[09단계 병합 후] V a l k y r i a </w>\n",
            "[10단계 병합 후] V a l k y r i a </w>\n",
            "\n",
            "최종 토큰화 결과: ['V', 'a', 'l', 'k', 'y', 'r', 'i', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentence(sentence, merge_rules):\n",
        "    words = sentence.split()\n",
        "    all_tokens = []\n",
        "    for word in words:\n",
        "        tokens = tokenize_by_wordpiece(word, merge_rules)\n",
        "        all_tokens.extend(tokens + [\"|\"])  # 단어 구분용 | 추가 (보기 편하게)\n",
        "    return all_tokens\n"
      ],
      "metadata": {
        "id": "YvwUThg6orVG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_sentence = \"Valkyria battle series\"\n",
        "final_tokens = tokenize_sentence(example_sentence, merge_history[:10])\n",
        "\n",
        "print(\"\\n전체 문장 토큰화 결과:\\n\", final_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM3gQE19o0d0",
        "outputId": "b7025887-f32e-4525-cdb9-31ad2b4e3542"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[초기 문자 단위 분해]\n",
            "Valkyria → V a l k y r i a </w>\n",
            "[01단계 병합 후] V a l k y r i a </w>\n",
            "[02단계 병합 후] V a l k y r i a </w>\n",
            "[03단계 병합 후] V a l k y r i a </w>\n",
            "[04단계 병합 후] V a l k y r i a </w>\n",
            "[05단계 병합 후] V a l k y r i a </w>\n",
            "[06단계 병합 후] V a l k y r i a </w>\n",
            "[07단계 병합 후] V a l k y r i a </w>\n",
            "[08단계 병합 후] V a l k y r i a </w>\n",
            "[09단계 병합 후] V a l k y r i a </w>\n",
            "[10단계 병합 후] V a l k y r i a </w>\n",
            "\n",
            "[초기 문자 단위 분해]\n",
            "battle → b a t t l e </w>\n",
            "[01단계 병합 후] b a t t l e</w>\n",
            "[02단계 병합 후] b a t t l e</w>\n",
            "[03단계 병합 후] b a t t l e</w>\n",
            "[04단계 병합 후] b a t t l e</w>\n",
            "[05단계 병합 후] b a t t l e</w>\n",
            "[06단계 병합 후] b a t t l e</w>\n",
            "[07단계 병합 후] b a t t l e</w>\n",
            "[08단계 병합 후] b a t t l e</w>\n",
            "[09단계 병합 후] b a t t l e</w>\n",
            "[10단계 병합 후] b a t t l e</w>\n",
            "\n",
            "[초기 문자 단위 분해]\n",
            "series → s e r i e s </w>\n",
            "[01단계 병합 후] s e r i e s </w>\n",
            "[02단계 병합 후] s e r i e s</w>\n",
            "[03단계 병합 후] s e r i e s</w>\n",
            "[04단계 병합 후] s e r i e s</w>\n",
            "[05단계 병합 후] s e r i e s</w>\n",
            "[06단계 병합 후] s er i e s</w>\n",
            "[07단계 병합 후] s er i e s</w>\n",
            "[08단계 병합 후] s er i e s</w>\n",
            "[09단계 병합 후] s er i e s</w>\n",
            "[10단계 병합 후] s er i e s</w>\n",
            "\n",
            "전체 문장 토큰화 결과:\n",
            " ['V', 'a', 'l', 'k', 'y', 'r', 'i', 'a', '|', 'b', 'a', 't', 't', 'l', 'e</w>', '|', 's', 'er', 'i', 'e', 's</w>', '|']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특수 토큰 5개를 먼저 정의합니다.\n",
        "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "\n",
        "# 사전 초기화\n",
        "vocab_dict = {}\n",
        "for index, token in enumerate(special_tokens):\n",
        "    vocab_dict[token] = index\n",
        "\n",
        "print(\"초기 vocab (특수 토큰 5개):\")\n",
        "print(vocab_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67CAXiago1fP",
        "outputId": "aa41e250-fc42-4782-96da-0ec63b175e95"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "초기 vocab (특수 토큰 5개):\n",
            "{'[PAD]': 0, '[UNK]': 1, '[CLS]': 2, '[SEP]': 3, '[MASK]': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 병합 규칙 기반으로 새로운 토큰 추가\n",
        "start_index = len(vocab_dict)\n",
        "\n",
        "for i, (left, right) in enumerate(merge_history):\n",
        "    new_token = left + right\n",
        "    vocab_dict[new_token] = start_index + i\n",
        "\n",
        "print(\"\\n병합된 토큰 10개 예시:\")\n",
        "for idx, (token, id_) in enumerate(vocab_dict.items()):\n",
        "    if idx < 15:\n",
        "        print(token, \":\", id_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhdPof6Po821",
        "outputId": "3cdea439-64a7-40dc-aa23-bacca30eeac0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "병합된 토큰 10개 예시:\n",
            "[PAD] : 0\n",
            "[UNK] : 1\n",
            "[CLS] : 2\n",
            "[SEP] : 3\n",
            "[MASK] : 4\n",
            "e</w> : 5\n",
            "s</w> : 6\n",
            "th : 7\n",
            "d</w> : 8\n",
            "n</w> : 9\n",
            "er : 10\n",
            "t</w> : 11\n",
            "the</w> : 12\n",
            "in : 13\n",
            "an : 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n최종 Vocab 크기:\", len(vocab_dict))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4P0knyoo-US",
        "outputId": "a2d4adb2-6cad-4209-966f-848e3c0000a2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "최종 Vocab 크기: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_tokens_to_ids(tokens, vocab):\n",
        "    \"\"\"\n",
        "    tokens: ['V', 'al', 'ky', 'ria']\n",
        "    vocab: 우리가 만든 vocab_dict\n",
        "    return: [숫자 리스트]\n",
        "    \"\"\"\n",
        "    token_ids = []\n",
        "    for t in tokens:\n",
        "        if t in vocab:\n",
        "            token_ids.append(vocab[t])\n",
        "        else:\n",
        "            token_ids.append(vocab[\"[UNK]\"])  # 모르는 토큰은 [UNK]\n",
        "    return token_ids\n"
      ],
      "metadata": {
        "id": "9m65fI-ppB0t"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_word = \"Valkyria\"\n",
        "tokens = tokenize_by_wordpiece(test_word, merge_history[:50])\n",
        "print(\"\\n토큰:\", tokens)\n",
        "\n",
        "token_ids = convert_tokens_to_ids(tokens, vocab_dict)\n",
        "print(\"ID 변환 결과:\", token_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1PF2LW-pD5G",
        "outputId": "29c94561-d139-4004-ca40-9eb4ebe13456"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[초기 문자 단위 분해]\n",
            "Valkyria → V a l k y r i a </w>\n",
            "[01단계 병합 후] V a l k y r i a </w>\n",
            "[02단계 병합 후] V a l k y r i a </w>\n",
            "[03단계 병합 후] V a l k y r i a </w>\n",
            "[04단계 병합 후] V a l k y r i a </w>\n",
            "[05단계 병합 후] V a l k y r i a </w>\n",
            "[06단계 병합 후] V a l k y r i a </w>\n",
            "[07단계 병합 후] V a l k y r i a </w>\n",
            "[08단계 병합 후] V a l k y r i a </w>\n",
            "[09단계 병합 후] V a l k y r i a </w>\n",
            "[10단계 병합 후] V a l k y r i a </w>\n",
            "\n",
            "토큰: ['V', 'a', 'l', 'k', 'y', 'r', 'i', 'a']\n",
            "ID 변환 결과: [1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "UY4XiFtBpFFP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(train_dataset[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfQkwwcLpN9H",
        "outputId": "523431ab-874e-4a38-9506-324dc035eb26"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 36718\n",
            "})\n",
            "{'text': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = train_dataset[3][\"text\"]\n",
        "print(\"원문:\", example_text)\n",
        "\n",
        "encoded = tokenizer(example_text)\n",
        "print(\"토큰 ID:\", encoded[\"input_ids\"])\n",
        "print(\"토큰 리스트:\", tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DakQdTSpeku",
        "outputId": "b9d80ba8-51aa-4cdf-88be-4dcaa14f2eb6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원문:  Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \n",
            "\n",
            "토큰 ID: [101, 12411, 5558, 2053, 11748, 4801, 4360, 1017, 1024, 4895, 2890, 27108, 5732, 11906, 1006, 2887, 1024, 1856, 1806, 1671, 30222, 30218, 30259, 30227, 30255, 30258, 30219, 2509, 1010, 5507, 1012, 11748, 4801, 4360, 1997, 1996, 11686, 1017, 1007, 1010, 4141, 3615, 2000, 2004, 11748, 4801, 4360, 11906, 3523, 2648, 2900, 1010, 2003, 1037, 8608, 2535, 1030, 1011, 1030, 2652, 2678, 2208, 2764, 2011, 16562, 1998, 2865, 1012, 4432, 2005, 1996, 9160, 12109, 1012, 2207, 1999, 2254, 2249, 1999, 2900, 1010, 2009, 2003, 1996, 2353, 2208, 1999, 1996, 11748, 4801, 4360, 2186, 1012, 15440, 1996, 2168, 10077, 1997, 8608, 1998, 2613, 1030, 1011, 1030, 2051, 11247, 2004, 2049, 16372, 1010, 1996, 2466, 3216, 5903, 2000, 1996, 2034, 2208, 1998, 4076, 1996, 1000, 2171, 3238, 1000, 1010, 1037, 18476, 2510, 3131, 3529, 1996, 3842, 1997, 26033, 2401, 2076, 1996, 2117, 12124, 2078, 2162, 2040, 4685, 3595, 2304, 3136, 1998, 2024, 25895, 2114, 1996, 4461, 3131, 1000, 10250, 8067, 3723, 10000, 1000, 1012, 102]\n",
            "토큰 리스트: ['[CLS]', 'sen', '##jo', 'no', 'val', '##ky', '##ria', '3', ':', 'un', '##re', '##cor', '##ded', 'chronicles', '(', 'japanese', ':', '戦', '場', 'の', '##ウ', '##ァ', '##ル', '##キ', '##ュ', '##リ', '##ア', '##3', ',', 'lit', '.', 'val', '##ky', '##ria', 'of', 'the', 'battlefield', '3', ')', ',', 'commonly', 'referred', 'to', 'as', 'val', '##ky', '##ria', 'chronicles', 'iii', 'outside', 'japan', ',', 'is', 'a', 'tactical', 'role', '@', '-', '@', 'playing', 'video', 'game', 'developed', 'by', 'sega', 'and', 'media', '.', 'vision', 'for', 'the', 'playstation', 'portable', '.', 'released', 'in', 'january', '2011', 'in', 'japan', ',', 'it', 'is', 'the', 'third', 'game', 'in', 'the', 'val', '##ky', '##ria', 'series', '.', 'employing', 'the', 'same', 'fusion', 'of', 'tactical', 'and', 'real', '@', '-', '@', 'time', 'gameplay', 'as', 'its', 'predecessors', ',', 'the', 'story', 'runs', 'parallel', 'to', 'the', 'first', 'game', 'and', 'follows', 'the', '\"', 'name', '##less', '\"', ',', 'a', 'penal', 'military', 'unit', 'serving', 'the', 'nation', 'of', 'gall', '##ia', 'during', 'the', 'second', 'europa', '##n', 'war', 'who', 'perform', 'secret', 'black', 'operations', 'and', 'are', 'pitted', 'against', 'the', 'imperial', 'unit', '\"', 'cal', '##ama', '##ty', 'raven', '\"', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        padding=\"max_length\",      # 모든 문장을 같은 길이로\n",
        "        truncation=True,           # 너무 긴 문장은 잘라내기\n",
        "        max_length=64              # 최대 길이 (원하면 조절)\n",
        "    )\n",
        "\n",
        "tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5d2e5d6bbbef473ea0680b97c5ba6ac4",
            "2b2407b780384cb3b831e1c81bc48f80",
            "f098c8a260d64249968bce6b7df7e146",
            "c083ef4c227b47e791327e83cf1aaaf8",
            "000998bc98254570949e8714ccb351cc",
            "9e7e382952ed41dfadcd028e1a1248a5",
            "d558b871cd9140b38de0d0a9dcf30e2e",
            "0ee7e026a9a14ff8b574b40374c4accd",
            "ad0ee927fe294379988dc2f6e10c66a6",
            "d8a68a810a8c47b0b42935ec78fe3c5f",
            "3390c0b6d8874474ab195f48554146c5"
          ]
        },
        "id": "Wm_soYdVpg0Z",
        "outputId": "c9c4de80-89da-46ac-d28d-4407a43e1e2e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d2e5d6bbbef473ea0680b97c5ba6ac4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9jtDsZ1pl-1",
        "outputId": "b2247fef-67d0-4f32-8f80-301f185dbbdc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': '', 'input_ids': [101, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"])\n"
      ],
      "metadata": {
        "id": "CBzQaOiYpsUo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(tokenized_dataset, batch_size=8, shuffle=True)\n",
        "batch = next(iter(train_loader))\n",
        "print(batch[\"input_ids\"].shape)   # (8, 64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cb2kO7upt9Z",
        "outputId": "5503beaf-bc59-4a31-cec6-15e83300088e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "8vOEYLkOpvWn"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256                # 임베딩 차원(D)\n",
        "number_of_layers = 4             # 인코더 레이어 개수(L)\n",
        "number_of_heads = 4              # 멀티헤드 개수(h). D % h == 0 이어야 합니다.\n",
        "intermediate_size = 1024         # FFN 내부 차원(보통 4*D)\n",
        "max_position_embeddings = 512    # 포지션 임베딩 길이\n",
        "type_vocab_size = 2              # 세그먼트 A/B\n",
        "layer_norm_eps = 1e-12           # LayerNorm 안정화용\n",
        "dropout_prob = 0.1               # 드롭아웃 확률\n",
        "\n",
        "vocab_size = tokenizer.vocab_size   # 토크나이저의 어휘 크기를 그대로 씁니다.\n"
      ],
      "metadata": {
        "id": "M_sgVzm3qFGh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertEmbeddings(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 hidden_size,\n",
        "                 max_position_embeddings,\n",
        "                 type_vocab_size,\n",
        "                 layer_norm_eps,\n",
        "                 dropout_prob):\n",
        "        super().__init__()  # 부모 클래스 초기화\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, hidden_size)             # 단어 임베딩\n",
        "        self.position_embeddings = nn.Embedding(max_position_embeddings, hidden_size)  # 위치 임베딩\n",
        "        self.token_type_embeddings = nn.Embedding(type_vocab_size, hidden_size)  # 세그먼트 임베딩\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size, eps=layer_norm_eps)          # 정규화\n",
        "        self.dropout = nn.Dropout(dropout_prob)                                  # 드롭아웃\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None):\n",
        "        batch_size, seq_len = input_ids.size()                                   # 크기 읽기\n",
        "\n",
        "        if token_type_ids is None:                                               # 세그먼트가 없으면\n",
        "            token_type_ids = torch.zeros_like(input_ids)                         # 전부 0으로\n",
        "\n",
        "        position_ids = torch.arange(seq_len, device=input_ids.device)            # [0..S-1]\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_len)     # (B,S)\n",
        "\n",
        "        word = self.word_embeddings(input_ids)                                   # (B,S,D)\n",
        "        pos = self.position_embeddings(position_ids)                             # (B,S,D)\n",
        "        tok = self.token_type_embeddings(token_type_ids)                         # (B,S,D)\n",
        "\n",
        "        x = word + pos + tok                                                     # 합치기\n",
        "        x = self.layer_norm(x)                                                   # 정규화\n",
        "        x = self.dropout(x)                                                      # 드롭아웃\n",
        "        return x                                                                 # (B,S,D)"
      ],
      "metadata": {
        "id": "1ebwfmrqqHGx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_attention_mask(attention_mask):\n",
        "    \"\"\"\n",
        "    attention_mask: (B,S), 1=유효, 0=패딩\n",
        "    반환: (B,1,1,S) 형태의 가중치. 0 위치는 큰 음수로 만들어 softmax에서 무시하게 함.\n",
        "    \"\"\"\n",
        "    if attention_mask is None:\n",
        "        return None\n",
        "    extended = attention_mask[:, None, None, :]             # (B,1,1,S)\n",
        "    extended = (1.0 - extended) * -10000.0                  # 유효=0, 패딩=-10000\n",
        "    return extended\n"
      ],
      "metadata": {
        "id": "ZXukXAAEqKH6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertSelfAttention(nn.Module):\n",
        "    def __init__(self, hidden_size, number_of_heads, dropout_prob):\n",
        "        super().__init__()\n",
        "        self.number_of_heads = number_of_heads\n",
        "        self.head_dim = hidden_size // number_of_heads\n",
        "        assert self.head_dim * number_of_heads == hidden_size  # 나누어떨어지는지 확인\n",
        "\n",
        "        self.query = nn.Linear(hidden_size, hidden_size)       # Q 투영\n",
        "        self.key   = nn.Linear(hidden_size, hidden_size)       # K 투영\n",
        "        self.value = nn.Linear(hidden_size, hidden_size)       # V 투영\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)                # 어텐션 확률 드롭아웃\n",
        "\n",
        "    def _split_heads(self, x):\n",
        "        # (B,S,D) -> (B,h,S,d)\n",
        "        B, S, D = x.size()\n",
        "        x = x.view(B, S, self.number_of_heads, self.head_dim).transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "    def _merge_heads(self, x):\n",
        "        # (B,h,S,d) -> (B,S,D)\n",
        "        B, h, S, d = x.size()\n",
        "        x = x.transpose(1, 2).contiguous().view(B, S, h * d)\n",
        "        return x\n",
        "\n",
        "    def forward(self, hidden_states, extended_attention_mask=None):\n",
        "        q = self._split_heads(self.query(hidden_states))                # (B,h,S,d)\n",
        "        k = self._split_heads(self.key(hidden_states))                  # (B,h,S,d)\n",
        "        v = self._split_heads(self.value(hidden_states))                # (B,h,S,d)\n",
        "\n",
        "        scores = torch.matmul(q, k.transpose(-1, -2)) / (self.head_dim ** 0.5)  # (B,h,S,S)\n",
        "\n",
        "        if extended_attention_mask is not None:                         # 패딩 가리기\n",
        "            scores = scores + extended_attention_mask                   # (B,h,S,S)\n",
        "\n",
        "        probs = F.softmax(scores, dim=-1)                               # 어텐션 분포\n",
        "        probs = self.dropout(probs)                                     # 드롭아웃\n",
        "\n",
        "        context = torch.matmul(probs, v)                                # (B,h,S,d)\n",
        "        context = self._merge_heads(context)                            # (B,S,D)\n",
        "        return context\n"
      ],
      "metadata": {
        "id": "PwZc9PRaqLqc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertSelfOutput(nn.Module):\n",
        "    def __init__(self, hidden_size, dropout_prob, layer_norm_eps):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(hidden_size, hidden_size)               # 출력 투영\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size, eps=layer_norm_eps)\n",
        "\n",
        "    def forward(self, attention_output, input_tensor):\n",
        "        x = self.dense(attention_output)                               # 선형\n",
        "        x = self.dropout(x)                                            # 드롭아웃\n",
        "        x = self.layer_norm(x + input_tensor)                          # 잔차 연결 + 정규화\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "R9HKRpcnqNVd"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertIntermediate(nn.Module):\n",
        "    def __init__(self, hidden_size, intermediate_size):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(hidden_size, intermediate_size)         # D -> 4D\n",
        "        self.act = nn.GELU()                                           # GELU 활성\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.dense(x))\n"
      ],
      "metadata": {
        "id": "uD305OBvqOTS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertOutput(nn.Module):\n",
        "    def __init__(self, intermediate_size, hidden_size, dropout_prob, layer_norm_eps):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(intermediate_size, hidden_size)         # 4D -> D\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size, eps=layer_norm_eps)\n",
        "\n",
        "    def forward(self, ff_output, input_tensor):\n",
        "        x = self.dense(ff_output)                                      # 선형\n",
        "        x = self.dropout(x)                                            # 드롭아웃\n",
        "        x = self.layer_norm(x + input_tensor)                          # 잔차 + 정규화\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "P8z6ywIRqPYH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertLayer(nn.Module):\n",
        "    def __init__(self, hidden_size, number_of_heads, intermediate_size, dropout_prob, layer_norm_eps):\n",
        "        super().__init__()\n",
        "        self.attn = BertSelfAttention(hidden_size, number_of_heads, dropout_prob)\n",
        "        self.attn_output = BertSelfOutput(hidden_size, dropout_prob, layer_norm_eps)\n",
        "        self.intermediate = BertIntermediate(hidden_size, intermediate_size)\n",
        "        self.output = BertOutput(intermediate_size, hidden_size, dropout_prob, layer_norm_eps)\n",
        "\n",
        "    def forward(self, hidden_states, extended_attention_mask):\n",
        "        attn_context = self.attn(hidden_states, extended_attention_mask)       # (B,S,D)\n",
        "        attn_out = self.attn_output(attn_context, hidden_states)               # (B,S,D)\n",
        "        inter = self.intermediate(attn_out)                                    # (B,S,4D)\n",
        "        layer_out = self.output(inter, attn_out)                               # (B,S,D)\n",
        "        return layer_out\n"
      ],
      "metadata": {
        "id": "EMw5Nu28qQRT"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self, hidden_size, number_of_layers, number_of_heads, intermediate_size, dropout_prob, layer_norm_eps):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            BertLayer(hidden_size, number_of_heads, intermediate_size, dropout_prob, layer_norm_eps)\n",
        "            for _ in range(number_of_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, hidden_states, extended_attention_mask):\n",
        "        for layer in self.layers:\n",
        "            hidden_states = layer(hidden_states, extended_attention_mask)       # 레이어 반복\n",
        "        return hidden_states\n"
      ],
      "metadata": {
        "id": "kLMGBgUdqRi0"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertPooler(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        cls = sequence_output[:, 0]                     # 첫 토큰(CLS) 벡터\n",
        "        pooled = self.activation(self.dense(cls))       # Linear+tanh\n",
        "        return pooled\n"
      ],
      "metadata": {
        "id": "VtC7uZ2GqSWG"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertModelMini(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.emb = BertEmbeddings(\n",
        "            vocab_size=vocab_size,\n",
        "            hidden_size=hidden_size,\n",
        "            max_position_embeddings=max_position_embeddings,\n",
        "            type_vocab_size=type_vocab_size,\n",
        "            layer_norm_eps=layer_norm_eps,\n",
        "            dropout_prob=dropout_prob\n",
        "        )\n",
        "        self.encoder = BertEncoder(\n",
        "            hidden_size=hidden_size,\n",
        "            number_of_layers=number_of_layers,\n",
        "            number_of_heads=number_of_heads,\n",
        "            intermediate_size=intermediate_size,\n",
        "            dropout_prob=dropout_prob,\n",
        "            layer_norm_eps=layer_norm_eps\n",
        "        )\n",
        "        self.pooler = BertPooler(hidden_size=hidden_size)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        x = self.emb(input_ids, token_type_ids)                         # (B,S,D)\n",
        "        ext_mask = build_attention_mask(attention_mask)                 # (B,1,1,S) or None\n",
        "        seq_out = self.encoder(x, ext_mask)                             # (B,S,D)\n",
        "        pooled = self.pooler(seq_out)                                   # (B,D)\n",
        "        return seq_out, pooled\n"
      ],
      "metadata": {
        "id": "5l6p5zT5qTPD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단 문장 두 개를 토크나이저로 인코딩합니다.\n",
        "encoded = tokenizer(\n",
        "    [\"hello bert model\", \"this is a tiny check\"],\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=16,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# 모델 생성 및 실행\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertModelMini().to(device)\n",
        "sequence_output, pooled_output = model(\n",
        "    input_ids=encoded[\"input_ids\"].to(device),\n",
        "    attention_mask=encoded[\"attention_mask\"].to(device),\n",
        "    token_type_ids=encoded[\"token_type_ids\"].to(device)\n",
        ")\n",
        "\n",
        "print(\"sequence_output:\", sequence_output.shape)  # 기대: (2, 16, 256)\n",
        "print(\"pooled_output:\", pooled_output.shape)      # 기대: (2, 256)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJTSJz8_qUvA",
        "outputId": "2ee69bc9-c009-4968-c5eb-641aca027c6d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sequence_output: torch.Size([2, 16, 256])\n",
            "pooled_output: torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "sample_texts = [\n",
        "    \"Hello BERT, how are you?\",\n",
        "    \"We are building BERT from scratch!\"\n",
        "]\n",
        "\n",
        "encoded_inputs = tokenizer(\n",
        "    sample_texts,\n",
        "    padding=\"max_length\",   # 길이 맞추기\n",
        "    truncation=True,        # 너무 긴 문장은 자르기\n",
        "    max_length=16,\n",
        "    return_tensors=\"pt\"     # PyTorch 텐서로\n",
        ")\n",
        "\n",
        "print(encoded_inputs.keys())\n",
        "print(encoded_inputs[\"input_ids\"].shape)  # (2, 16)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpGJrOjyqWMO",
        "outputId": "dc9e0390-cc29-4216-e0c9-e85569983735"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeysView({'input_ids': tensor([[  101,  7592, 14324,  1010,  2129,  2024,  2017,  1029,   102,     0,\n",
            "             0,     0,     0,     0,     0,     0],\n",
            "        [  101,  2057,  2024,  2311, 14324,  2013, 11969,   999,   102,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])})\n",
            "torch.Size([2, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성 (앞서 만든 BertModelMini)\n",
        "model = BertModelMini()\n",
        "\n",
        "sequence_output, pooled_output = model(\n",
        "    input_ids=encoded_inputs[\"input_ids\"],\n",
        "    attention_mask=encoded_inputs[\"attention_mask\"],\n",
        "    token_type_ids=encoded_inputs[\"token_type_ids\"]\n",
        ")\n",
        "\n",
        "print(\"sequence_output:\", sequence_output.shape)\n",
        "print(\"pooled_output:\", pooled_output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smvvHxq7qfJv",
        "outputId": "de2aea2e-bd4d-4eec-843e-31c57f2cba4d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sequence_output: torch.Size([2, 16, 256])\n",
            "pooled_output: torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"BERT model test\"\n",
        "tokens = tokenizer.tokenize(text)\n",
        "ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "sequence_output, pooled_output = model(ids)\n",
        "\n",
        "print(\"입력 토큰:\", tokens)\n",
        "print(\"CLS 벡터(문장 표현):\", pooled_output[0][:10])  # 앞부분 10차원만 보기\n",
        "print(\"첫 단어 벡터 크기:\", sequence_output[0, 1].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5Y7EZ5bqgr2",
        "outputId": "ae0ee769-31cd-4ef8-a50c-2e350f268f4e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 토큰: ['bert', 'model', 'test']\n",
            "CLS 벡터(문장 표현): tensor([-0.1715, -0.2545, -0.4214,  0.3750,  0.0172, -0.5693,  0.3434, -0.0537,\n",
            "        -0.1521, -0.0163], grad_fn=<SliceBackward0>)\n",
            "첫 단어 벡터 크기: torch.Size([256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertPredictionHeadTransform(nn.Module):\n",
        "    def __init__(self, hidden_size, layer_norm_eps):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
        "        self.act = nn.GELU()\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size, eps=layer_norm_eps)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.act(hidden_states)\n",
        "        hidden_states = self.layer_norm(hidden_states)\n",
        "        return hidden_states\n"
      ],
      "metadata": {
        "id": "EZlol0c_qixu"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertLMPredictionHead(nn.Module):\n",
        "    def __init__(self, hidden_size, vocab_size, layer_norm_eps):\n",
        "        super().__init__()\n",
        "        self.transform = BertPredictionHeadTransform(hidden_size, layer_norm_eps)\n",
        "        self.decoder = nn.Linear(hidden_size, vocab_size, bias=False)  # 가중치 타이잉 대상\n",
        "        self.bias = nn.Parameter(torch.zeros(vocab_size))              # 출력 바이어스\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.transform(hidden_states)     # (B,S,D)\n",
        "        logits = self.decoder(hidden_states) + self.bias  # (B,S,V)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "3w7RvaOcqse4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForMaskedLMMini(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super().__init__()\n",
        "        self.bert = base_model                                     # 우리가 만든 BertModelMini\n",
        "        self.cls = BertLMPredictionHead(hidden_size, vocab_size, layer_norm_eps)\n",
        "        # 가중치 타이잉: decoder.weight ↔ word_embeddings.weight\n",
        "        self.cls.decoder.weight = self.bert.emb.word_embeddings.weight\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        sequence_output, _ = self.bert(input_ids, attention_mask, token_type_ids)  # (B,S,D)\n",
        "        logits = self.cls(sequence_output)                                         # (B,S,V)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # CrossEntropyLoss(ignore_index=-100) → -100 위치는 로스 제외\n",
        "            loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "            loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
        "        return logits, loss\n"
      ],
      "metadata": {
        "id": "8PnQncdRqtog"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_mlm_inputs_and_labels(input_ids, tokenizer, mlm_probability=0.15):\n",
        "    \"\"\"\n",
        "    input_ids: (B,S) LongTensor\n",
        "    반환: masked_input_ids, labels  (둘 다 (B,S))\n",
        "    규칙: 15% 위치만 정답으로 학습\n",
        "          그중 80% → [MASK], 10% → 랜덤 토큰, 10% → 원래 토큰 유지\n",
        "    \"\"\"\n",
        "    input_ids = input_ids.clone()\n",
        "    labels = input_ids.clone()\n",
        "\n",
        "    special_ids = set([\n",
        "        tokenizer.cls_token_id,\n",
        "        tokenizer.sep_token_id,\n",
        "        tokenizer.pad_token_id if tokenizer.pad_token_id is not None else -1\n",
        "    ])\n",
        "\n",
        "    # 마스크 후보(스페셜 토큰 제외)\n",
        "    probability_matrix = torch.full(labels.shape, mlm_probability, device=labels.device)\n",
        "    special_mask = torch.zeros_like(labels, dtype=torch.bool, device=labels.device) # special_mask도 labels와 동일 장치로 생성\n",
        "    for sid in special_ids:\n",
        "        if sid >= 0:\n",
        "            special_mask |= (labels == sid)\n",
        "\n",
        "    probability_matrix.masked_fill_(special_mask, 0.0)\n",
        "\n",
        "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
        "    labels[~masked_indices] = -100  # 정답으로 쓰지 않을 위치는 -100\n",
        "\n",
        "    # 80%: [MASK]\n",
        "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8, device=labels.device)).bool() & masked_indices # torch.full 결과도 labels와 동일 장치로\n",
        "    input_ids[indices_replaced] = tokenizer.mask_token_id\n",
        "\n",
        "    # 10%: 랜덤 토큰\n",
        "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5, device=labels.device)).bool() & masked_indices & ~indices_replaced # torch.full 결과도 labels와 동일 장치로\n",
        "    random_words = torch.randint(vocab_size, labels.shape, dtype=torch.long, device=labels.device) # 랜덤 토큰도 동일 장치로\n",
        "    input_ids[indices_random] = random_words[indices_random]\n",
        "\n",
        "    # 나머지 10%: 원래 토큰 유지 (입력 그대로)\n",
        "\n",
        "    return input_ids, labels"
      ],
      "metadata": {
        "id": "Xqof4hZlqu8m"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "sample_sentences = [\n",
        "    \"this is a tiny masked language modeling test\",\n",
        "    \"we are building a bert model from scratch\"\n",
        "]\n",
        "\n",
        "encoded_batch = tokenizer(\n",
        "    sample_sentences,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=24,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "masked_input_ids, mlm_labels = make_mlm_inputs_and_labels(encoded_batch[\"input_ids\"], tokenizer)\n",
        "attention_mask = encoded_batch[\"attention_mask\"]\n",
        "token_type_ids = encoded_batch[\"token_type_ids\"]\n"
      ],
      "metadata": {
        "id": "KtXEcA9Hqv-l"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 만들기\n",
        "base_model = BertModelMini()\n",
        "mlm_model = BertForMaskedLMMini(base_model)\n",
        "\n",
        "# 옵티마이저\n",
        "optimizer = torch.optim.AdamW(mlm_model.parameters(), lr=5e-5)\n",
        "\n",
        "# 순전파 → 손실\n",
        "mlm_model.train()\n",
        "logits, loss = mlm_model(\n",
        "    input_ids=masked_input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    token_type_ids=token_type_ids,\n",
        "    labels=mlm_labels\n",
        ")\n",
        "print(\"초기 손실:\", float(loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiVKjcqIqxSJ",
        "outputId": "bd7da3dc-5b67-45be-9832-6dedebce438c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "초기 손실: 62.507568359375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 역전파 → 가중치 갱신\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()\n",
        "print(\"한 스텝 업데이트 완료 ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srin2yYjqynX",
        "outputId": "e5194f63-9e66-42b8-b72c-a83b1ac1302b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한 스텝 업데이트 완료 ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 추론 모드로 전환\n",
        "mlm_model.eval()\n",
        "with torch.no_grad():\n",
        "    logits, _ = mlm_model(\n",
        "        input_ids=masked_input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids=token_type_ids\n",
        "    )\n",
        "    predictions = logits.argmax(-1)  # (B,S)\n",
        "\n",
        "# 첫 문장 기준으로, 마스크된 위치만 비교 출력\n",
        "batch_index = 0\n",
        "masked_positions = (mlm_labels[batch_index] != -100).nonzero(as_tuple=True)[0].tolist()\n",
        "\n",
        "print(\"\\n[예측 결과(일부 마스크 위치)]\")\n",
        "for pos in masked_positions[:5]:  # 5개까지만 보기\n",
        "    pred_id = predictions[batch_index, pos].item()\n",
        "    gold_id = mlm_labels[batch_index, pos].item()\n",
        "    print(f\"pos={pos:2d}  pred={tokenizer.decode([pred_id])!r}  gold={tokenizer.decode([gold_id])!r}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeQqBOz4qz6-",
        "outputId": "2886b0c6-60d4-43a3-d33b-fbf4596dba79"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[예측 결과(일부 마스크 위치)]\n",
            "pos= 1  pred='##チ'  gold='this'\n",
            "pos= 2  pred='mo'  gold='is'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "metadata": {
        "id": "a9FU8HZJq1NG"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장을 고정 길이로 인코딩합니다.\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=64   # 필요에 따라 128/256으로 조정 가능\n",
        "    )\n",
        "\n",
        "tokenized_training_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n"
      ],
      "metadata": {
        "id": "K-SFXtCSq9ib"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 텐서로 바로 쓰기 위해 포맷 설정\n",
        "tokenized_training_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"]\n",
        ")\n",
        "\n",
        "print(\"샘플 확인:\", {k: v.shape if hasattr(v, \"shape\") else type(v) for k, v in tokenized_training_dataset[0].items()})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAqD1RDTq-aS",
        "outputId": "80bdc84e-e854-4392-f911-95168fb1711a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플 확인: {'input_ids': torch.Size([64]), 'token_type_ids': torch.Size([64]), 'attention_mask': torch.Size([64])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "training_loader = DataLoader(tokenized_training_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 배치 모양 확인\n",
        "first_batch = next(iter(training_loader))\n",
        "for key, value in first_batch.items():\n",
        "    print(key, value.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK4bfILXrBqX",
        "outputId": "a2a03675-dd13-48fe-b256-ba59646d0c55"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids torch.Size([32, 64])\n",
            "token_type_ids torch.Size([32, 64])\n",
            "attention_mask torch.Size([32, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "base_model = BertModelMini().to(device)\n",
        "mlm_model = BertForMaskedLMMini(base_model).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(mlm_model.parameters(), lr=5e-5)\n"
      ],
      "metadata": {
        "id": "8xz9-FOwrCr4"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbf4696a",
        "outputId": "1e600531-1102-4e2a-bad5-cae42ff84f4d"
      },
      "source": [
        "mlm_model.train()\n",
        "\n",
        "max_train_steps = 300          # 처음엔 가볍게 300스텝만\n",
        "log_interval = 50              # 50스텝마다 로그 출력\n",
        "\n",
        "step_counter = 0\n",
        "\n",
        "# 데이터 로더를 다시 초기화하여 처음부터 학습 시작\n",
        "training_loader = DataLoader(tokenized_training_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "for one_batch in training_loader:\n",
        "    if step_counter >= max_train_steps:\n",
        "        break\n",
        "\n",
        "    input_ids = one_batch[\"input_ids\"].to(device)\n",
        "    attention_mask = one_batch[\"attention_mask\"].to(device)\n",
        "    token_type_ids = one_batch[\"token_type_ids\"].to(device)\n",
        "\n",
        "    # 표준 15% 마스킹을 즉석 적용\n",
        "    masked_input_ids, mlm_labels = make_mlm_inputs_and_labels(input_ids, tokenizer)\n",
        "\n",
        "    masked_input_ids = masked_input_ids.to(device)\n",
        "    mlm_labels = mlm_labels.to(device)\n",
        "\n",
        "    # 순전파\n",
        "    logits, loss = mlm_model(\n",
        "        input_ids=masked_input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids=token_type_ids,\n",
        "        labels=mlm_labels\n",
        "    )\n",
        "\n",
        "    # 역전파\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(mlm_model.parameters(), max_norm=1.0)  # 안정성용(선택)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    step_counter += 1\n",
        "    if step_counter % log_interval == 0:\n",
        "        print(f\"[step {step_counter:4d}] loss = {float(loss):.4f}\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[step   50] loss = 40.1848\n",
            "[step  100] loss = 36.0620\n",
            "[step  150] loss = 32.3814\n",
            "[step  200] loss = 32.8065\n",
            "[step  250] loss = 29.4431\n",
            "[step  300] loss = 29.2984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlm_model.eval()\n",
        "with torch.no_grad():\n",
        "    # 새 문장을 준비합니다.\n",
        "    sample_sentences = [\"this is a simple masked language modeling check\"]\n",
        "    batch_for_eval = tokenizer(sample_sentences, padding=\"max_length\", truncation=True, max_length=20, return_tensors=\"pt\")\n",
        "\n",
        "    # 평가에서도 마스크를 적용해봅니다.\n",
        "    eval_masked_input_ids, eval_labels = make_mlm_inputs_and_labels(batch_for_eval[\"input_ids\"], tokenizer)\n",
        "\n",
        "    logits, _ = mlm_model(\n",
        "        input_ids=eval_masked_input_ids.to(device),\n",
        "        attention_mask=batch_for_eval[\"attention_mask\"].to(device),\n",
        "        token_type_ids=batch_for_eval[\"token_type_ids\"].to(device)\n",
        "    )\n",
        "    predictions = logits.argmax(-1).cpu()\n",
        "\n",
        "# 마스크된 위치들만 몇 개 출력\n",
        "masked_positions = (eval_labels[0] != -100).nonzero(as_tuple=True)[0].tolist()\n",
        "print(\"\\n[예측 결과 — 마스크된 위치 5개]\")\n",
        "for pos in masked_positions[:5]:\n",
        "    gold_id = eval_labels[0, pos].item()\n",
        "    pred_id = predictions[0, pos].item()\n",
        "    print(f\"pos={pos:2d}  pred={tokenizer.decode([pred_id])!r}  gold={tokenizer.decode([gold_id])!r}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiGNM2j9rNpW",
        "outputId": "4c85f35f-17d3-4fd2-ce7d-2c4f6e9fe141"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[예측 결과 — 마스크된 위치 5개]\n",
            "pos= 3  pred='in'  gold='a'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Km-8o_uzrc8n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}